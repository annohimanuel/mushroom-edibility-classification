<h1 align="center">ğŸ„ Mushroom Edibility Classification (Neural Network + PCA)</h1>

<p align="center">
  <b>Binary classifier</b> to predict whether a mushroom is <span title="Safe to eat">âœ… edible</span> or <span title="Dangerous">â˜ ï¸ poisonous</span> using the classic <b>Agaricusâ€“Lepiota</b> dataset.
</p>

<p align="center">
  <img alt="Python" src="https://img.shields.io/badge/Python-3.x-informational">
  <img alt="TensorFlow" src="https://img.shields.io/badge/TensorFlow-Keras-informational">
  <img alt="scikit-learn" src="https://img.shields.io/badge/scikit--learn-ML-informational">
  <img alt="License" src="https://img.shields.io/badge/License-MIT-lightgrey">
</p>

---

## ğŸ¯ Project Objective

Misclassifying a poisonous mushroom as edible is high-risk.  
Goal: predict the label:

- **Target:** `class`
  - `e` = edible âœ…
  - `p` = poisonous â˜ ï¸

---

## ğŸ“¦ Dataset

ğŸ“š **Source:** The Audubon Society Field Guide to North American Mushrooms (1981)  
ğŸ“„ Files:
- `data/agaricus-lepiota.csv`
- `data/agaricus-lepiota.names` (feature reference)

ğŸ“Š **Rows:** 8,124  
ğŸ§© **Features:** 22 categorical attributes (nominal)

> The `.names` file is used for understanding the dataset, not training.

---

## âš¡ Quick Highlights

âœ… Fully categorical data â†’ **One-hot encoding**  
ğŸ§  Neural network baseline (Dense â†’ Dense)  
ğŸ§ª Evaluation via **Confusion Matrix**  
ğŸ§Š PCA retains **95% variance** while shrinking features  
ğŸ“‰ Feature count reduced **94 â†’ 38** with near-identical performance

---

## ğŸ”¬ Workflow

### 1) Data Validation âœ…
- Loaded dataset + confirmed no nulls using `isnull().sum()`

### 2) Train/Test Split âœ‚ï¸
- 80/20 split with stratification to preserve class balance

### 3) Encoding ğŸ”
- One-hot encode categorical features (`pd.get_dummies(drop_first=True)`)
- Label encode target (`LabelEncoder`): `0=edible`, `1=poisonous`
- Align train/test columns via `reindex(..., fill_value=0)`

### 4) Baseline Neural Network ğŸ§ 
Architecture:
- Dense(32, ReLU) â†’ Dense(1, Sigmoid)

Training:
- Adam + Binary Cross Entropy
- 20 epochs + validation split
- Tracked training time with `%%time`

Evaluation:
- Threshold at 0.5
- Confusion matrix

<p align="center">
  <img src="assets/confusion_matrix_baseline.png" alt="Confusion Matrix - Baseline" width="520">
</p>

### 5) PCA Dimensionality Reduction ğŸ§Š
- PCA retaining **95% variance**
- Features reduced from **94 â†’ 38**

<p align="center">
  <img src="assets/pca_variance.png" alt="PCA Variance Explained" width="520">
</p>

### 6) PCA Neural Network âš™ï¸
Architecture:
- Dense(16, ReLU) â†’ Dense(1, Sigmoid)

Evaluation:
- Confusion matrix

<p align="center">
  <img src="assets/confusion_matrix_pca.png" alt="Confusion Matrix - PCA Model" width="520">
</p>

---

## ğŸ Results

| Model | Features | Train Time (20 epochs) | Test Accuracy | Notes |
|------:|---------:|------------------------:|--------------:|------|
| Baseline NN | 94 | ~1.82s | ~1.0000 | No FP/FN observed |
| PCA NN (95% var) | 38 | ~1.65s | ~0.9996 | No FP/FN observed |

âœ… PCA delivered a major dimensionality reduction with negligible performance loss.

---

ğŸ‘¤ Author

Imanuel Annoh
GitHub: https://github.com/annohimanuel
